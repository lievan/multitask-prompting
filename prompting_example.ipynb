{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "WDv4-4XfczAN"
      },
      "outputs": [],
      "source": [
        "from prompt import Prompt, RobertaPrompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5Mq5nlxdlNu"
      },
      "source": [
        "### Define the Prompt\n",
        "\n",
        "We define a prompt that can perform two tasks given a topic and an argument <br>\n",
        "1) classify whether the argument is a fallacy, and if so what fallacy the argument contains <br>\n",
        "2) decide whether the argument supports or refutes the topic <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "ZLIUPefZB8Bu"
      },
      "outputs": [],
      "source": [
        "templates = {\"fallacy\": \"fallacy task. Topic: {} Text: {} This contains the fallacy: {}\", \n",
        "             \"stance\": \"procon task. Topic: {} Text: {} Has the relation: {}\"}\n",
        "\n",
        "def fallacy_policy(pred):\n",
        "  fallacies = {'AppealtoEmotion', 'RedHerring', 'NoFallacy', 'IrrelevantAuthority','AdHominem','HastyGeneralization'}\n",
        "  if pred not in fallacies: return 'UNKNOWN'\n",
        "  return pred\n",
        "def stance_policy(pred):\n",
        "  if pred not in {\"support\", \"contradict\"}: return \"UNKNOWN\"\n",
        "  return pred\n",
        "\n",
        "policies = {\"fallacy\": fallacy_policy, \"stance\": stance_policy}\n",
        "\n",
        "argument_prompt = Prompt(templates, policies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GnB9BUHfT0o"
      },
      "source": [
        "RobertaPrompt uses this class to convert a sample into it's desire prompt - for example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GXLu5H6hfR85",
        "outputId": "938c3fe7-14ca-4ac2-af5a-f5af87f0cdc0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fallacy task. Topic: Should we allow animal testing? Text: Animal testing abuses animals and should be dis-continued This contains the fallacy: <mask>'"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "argument_prompt.test_sample([\"Should we allow animal testing?\", \"Animal testing abuses animals and should be dis-continued\"], \"fallacy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEgFVKDueKMd"
      },
      "source": [
        "### Load Model\n",
        "We load a model we have already trained for this task: here are sample predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "eZn5mZMuQQjz"
      },
      "outputs": [],
      "source": [
        "pmodel = RobertaPrompt(model = '/Laidlaw Research Project/models/prompt_combined', device = torch.device('cuda'), prompt = argument_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLkf_WLyW8zg",
        "outputId": "9de0abb6-7b44-44de-85a5-8ad982f22560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fallacy: NoFallacy\n",
            "Stance: contradict\n"
          ]
        }
      ],
      "source": [
        "fallacy = pmodel.infer([\"Should we allow animal testing?\", \"Animal testing abuses animals and should be dis-continued\"], \"fallacy\")\n",
        "stance = pmodel.infer([\"Should we allow animal testing?\", \"Animal testing abuses animals and should be dis-continued\"], \"stance\")\n",
        "print(\"Fallacy: {}\\nStance: {}\".format(fallacy, stance))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MRzsviaenxX",
        "outputId": "870a6baf-3662-4acd-ee58-6d7cc8cd1b0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fallacy: AdHominem\n",
            "Stance: contradict\n"
          ]
        }
      ],
      "source": [
        "fallacy = pmodel.infer([\"Should we allow animal testing?\", \"Your stupid for bringing this up, animal testing is horrible\"], \"fallacy\")\n",
        "stance = pmodel.infer([\"Should we allow animal testing?\", \"Your stupid for bringing this up, animal testing is horrible\"], \"stance\")\n",
        "print(\"Fallacy: {}\\nStance: {}\".format(fallacy, stance))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58wuvAv3evt9",
        "outputId": "95f6159c-b738-4f70-c9ab-5c3d639adcc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fallacy: IrrelevantAuthority\n",
            "Stance: support\n"
          ]
        }
      ],
      "source": [
        "fallacy = pmodel.infer([\"Should we allow animal testing?\", \"My Dad had a dog once, he says animal testing should be allowed\"], \"fallacy\")\n",
        "stance = pmodel.infer([\"Should we allow animal testing?\", \"My Dad had a dog once, he says animal testing should be allowed\"], \"stance\")\n",
        "print(\"Fallacy: {}\\nStance: {}\".format(fallacy, stance))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l77z7efUe4xX",
        "outputId": "5cca35f9-4f2f-4e97-f292-e8e0835bae75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fallacy: RedHerring\n",
            "Stance: support\n"
          ]
        }
      ],
      "source": [
        "fallacy = pmodel.infer([\"Should we allow animal testing?\", \"Everyone has a favorite animal, what is yours?\"], \"fallacy\")\n",
        "stance = pmodel.infer([\"Should we allow animal testing?\", \"Everyone has a favorite animal, what is yours?\"], \"stance\")\n",
        "print(\"Fallacy: {}\\nStance: {}\".format(fallacy, stance))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUwprAyYiJmm"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "Fs2FJwbmiKwM"
      },
      "outputs": [],
      "source": [
        "pmodel = RobertaPrompt(model='roberta-large', device = torch.device('cuda'), prompt = argument_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkYSvBpmnwCy"
      },
      "outputs": [],
      "source": [
        "pmodel.train(\"sample_train_set.tsv\", \"sample_val_set.tsv\", output_dir=\"sample_model\", epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o3GJocynwZg"
      },
      "outputs": [],
      "source": [
        "pmodel.test(\"sample_test_set.tsv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
